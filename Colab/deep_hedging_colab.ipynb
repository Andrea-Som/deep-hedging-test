{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_hedging_colab",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5gJZ4fINGMVtA2n35v+Qi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuMan-Tam/deep-hedging-demo/blob/master/Colab/deep_hedging_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMnI5JIocCaD",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "5e8e352e-94b9-4a87-93f6-36f2a3861f38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#@title <font color='Blue'>**Overheads**</font>\n",
        "\n",
        "# Author: Yu-Man Tam\n",
        "# Last updated: 4/10/2020\n",
        "\n",
        "# Reference: Deep Hedging (2019, Quantitative Finance) by Buehler et al.\n",
        "# https://www.tandfonline.com/doi/abs/10.1080/14697688.2019.1571683\n",
        "\n",
        "!apt-get update --fix-missing\n",
        "!apt-get -qq install -y libquantlib0-dev\n",
        "!pip -q install QuantLib tqdm==4.41.1\n",
        "\n",
        "from tqdm import trange\n",
        "from tqdm.keras import TqdmCallback\n",
        "from IPython.display import Math, HTML, clear_output\n",
        "\n",
        "import numpy as np\n",
        "import QuantLib as ql\n",
        "import tensorflow as tf\n",
        "from itertools import repeat\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, \\\n",
        "                                            ReduceLROnPlateau\n",
        "from tensorflow.compat.v1.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import custom modules from github\n",
        "!rm -rf deep-hedging-demo\n",
        "!git clone https://github.com/YuMan-Tam/deep-hedging-demo\n",
        "\n",
        "import sys, os\n",
        "sys.path.insert(0, os.getcwd() + \"/deep-hedging-demo/lib\")\n",
        "\n",
        "from stochastic_processes import BlackScholesProcess\n",
        "from instruments import European_Call\n",
        "from deep_hedging import Deep_Hedging_Model\n",
        "from loss_metrics import Entropy, CVaR\n",
        "from utilities import train_test_split\n",
        "\n",
        "%load_ext autoreload\n",
        "\n",
        "clear_output()\n",
        "print(\"\\nFinish installing and importing all necessary libraries!\")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Finish installing and importing all necessary libraries!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GptSMgcl525K",
        "colab_type": "text"
      },
      "source": [
        "**Import all neccessary python, quantitative finance, and machine learning software libraries.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uusmc7_Uc4wN",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title <font color='Blue'>**User Inputs**</font>\n",
        "\n",
        "# Geometric Brownian Motion.\n",
        "N = 30 # Number of time steps (in days)\n",
        "\n",
        "S0 = 100.0 # Stock price at time = 0\n",
        "sigma = 0.2 # Implied volatility\n",
        "risk_free = 0.0 # Risk-free rate\n",
        "dividend = 0.0 # Continuous dividend yield\n",
        "\n",
        "Ktrain = 1*(10**5) # Size of training sample.\n",
        "Ktest_ratio = 0.2 # Fraction of training sample as testing sample.\n",
        "\n",
        "# European call option (short).\n",
        "strike = S0\n",
        "payoff_func = lambda x: -np.maximum(x - strike, 0.0)\n",
        "calculation_date = ql.Date.todaysDate()\n",
        "maturity_date = ql.Date.todaysDate() + N\n",
        "\n",
        "# Day convention.\n",
        "day_count = ql.Actual365Fixed() # Actual/Actual (ISDA)\n",
        "\n",
        "# Proportional transaction cost.\n",
        "epsilon = np.power(2.0,-8)*0.0                 \n",
        "\n",
        "# Information set (in string)\n",
        "# Choose from: S, log_S, normalized_log_S (by S0)\n",
        "information_set = \"normalized_log_S\"\n",
        "\n",
        "# Loss function\n",
        "# loss_type = \"CVaR\" (Expected Shortfall) -> loss_param = alpha \n",
        "# loss_type = \"Entropy\" -> loss_param = lambda\n",
        "loss_type = \"Entropy\"\n",
        "loss_param = 1.0\n",
        "\n",
        "# Neural network (NN) structure\n",
        "m = 15 # Number of neurons in each hidden layer.\n",
        "d = 3 # Number of hidden layers (Note including input nor output layer)         \n",
        "\n",
        "# Neural network training parameters\n",
        "lr = 1e-2 # Learning rate\n",
        "batch_size=256 # Batch size\n",
        "epochs=50 # Number of epochs\n",
        "\n",
        "# Other parameters\n",
        "use_batch_norm = False\n",
        "kernel_initializer = \"he_uniform\"\n",
        "\n",
        "activation_dense = \"leaky_relu\"\n",
        "activation_output = \"sigmoid\"\n",
        "final_period_cost = False\n",
        "\n",
        "# Other control flags for development purpose.\n",
        "mc_simulator = \"QuantLib\" # \"QuantLib\" or \"Numpy\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR8SZiGi7Ygm",
        "colab_type": "text"
      },
      "source": [
        "**Provide input parameters for Monte Carlo simulation, call option, transaction cost, loss function, and deep hedging algorithm.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuLfzImssxVz",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title <font color='Blue'>**Monte Carlo Simulation - Generate Random Paths of Stock Prices**</font>\n",
        "%autoreload 2\n",
        "\n",
        "seed = 0 # Random seed. Change to have deterministic outcome.\n",
        "\n",
        "# Total obs = Training + Testing\n",
        "nobs = int(Ktrain*(1+Ktest_ratio)) \n",
        "\t\t\n",
        "# Length of one time-step (as fraction of a year).\n",
        "dt = day_count.yearFraction(calculation_date,calculation_date + 1) \n",
        "maturity = N*dt # Maturities (in the unit of a year)\n",
        "\n",
        "stochastic_process = BlackScholesProcess(s0 = S0, sigma = sigma, risk_free = risk_free, \\\n",
        "                        dividend = dividend, day_count = day_count, seed=seed)\n",
        "\n",
        "S = stochastic_process.gen_path(maturity, N, nobs)\n",
        "\n",
        "print(\"\\n\\ns0 = \" + str(S0))\n",
        "print(\"sigma = \" + str(sigma))\n",
        "print(\"risk_free = \" + str(risk_free) + \"\\n\")\n",
        "print(\"Number of time steps = \" + str(N))\n",
        "print(\"Length of each time step = \" + \"1/365\\n\")\n",
        "print(\"Simulation Done!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3PXslQawKv1",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "c0b10c55-8549-47a4-c94d-0071686bd1aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title <font color='Blue'>**Prepare data to be fed into the deep hedging algorithm.**</font>\n",
        "\n",
        "payoff_T = payoff_func(S[:,-1]) # Payoff of the call option\n",
        "\n",
        "trade_set =  np.stack((S),axis=1) # Trading set\n",
        "\n",
        "if information_set is \"S\":\n",
        "  I =  np.stack((S),axis=1) # Information set\n",
        "elif information_set is \"log_S\":\n",
        "  I =  np.stack((np.log(S)),axis=1)\n",
        "elif information_set is \"normalized_log_S\":\n",
        "  I =  np.stack((np.log(S/S0)),axis=1)\n",
        "\n",
        "# Structure of xtrain:\n",
        "#   1) Trade set: [S]\n",
        "#   2) Information set: [S] \n",
        "#   3) payoff (dim = 1)\n",
        "x_all = []\n",
        "for i in range(N+1):\n",
        "  x_all += [trade_set[i,:,None]]\n",
        "  if i != N:\n",
        "    x_all += [I[i,:,None]]\n",
        "x_all += [payoff_T[:,None]]\n",
        "\n",
        "# Split the entire sample into a training sample and a testing sample.\n",
        "test_size = int(Ktrain*Ktest_ratio)\n",
        "[xtrain, xtest] = train_test_split(x_all, test_size=test_size)\n",
        "[S_train, S_test] = train_test_split([S], test_size=test_size)\n",
        "[option_payoff_train, option_payoff_test] = \\\n",
        "    train_test_split([x_all[-1]], test_size=test_size)\n",
        "\n",
        "print(\"Finish preparing data!\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finish preparing data!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og9G8QwMvk0V",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "dbf32288-d5c6-46fd-d806-e3763d5ec6d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "#@title <font color='Blue'>**Run the Deep Hedging Algorithm (Simple Network)!**</font>\n",
        "strategy_type = \"simple\"\n",
        "optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "# Setup and compile the model\n",
        "model_simple = Deep_Hedging_Model(N=N, d=d+2, m=m, risk_free=risk_free, \\\n",
        "          dt = dt, strategy_type=\"simple\", epsilon = epsilon, \\\n",
        "          use_batch_norm = use_batch_norm, kernel_initializer = kernel_initializer, \\\n",
        "          activation_dense = activation_dense, activation_output = activation_output, \\\n",
        "          final_period_cost = final_period_cost, output_type=\"colab\", \\\n",
        "          loss_type=loss_type, loss_param=loss_param)\n",
        "\n",
        "certainty_equiv = tf.Variable(0.0, name = \"certainty_equiv\")\n",
        "loss = Entropy(model_simple.output, certainty_equiv, loss_param)\n",
        "model_simple.add_loss(loss)\n",
        "\n",
        "model_simple.compile(optimizer=optimizer)\n",
        "\n",
        "# Stopping criteria\n",
        "model_data_dir =\"./data/\"\n",
        "best_model_file = model_data_dir + \\\n",
        "          \"model_\" + strategy_type + \"_\"  + str(epsilon) + \".h5\"\n",
        "\n",
        "early_stopping = EarlyStopping(monitor=\"loss\", \\\n",
        "          patience=10, min_delta=1e-4, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"loss\", \\\n",
        "          factor=0.9, patience=2, min_delta=1e-3, verbose=0)\n",
        "model_checkpoint = ModelCheckpoint(best_model_file, \\\n",
        "          monitor=\"loss\", save_best_only=True, \\\n",
        "          save_weights_only=False, verbose=0)\n",
        "\n",
        "callbacks = [early_stopping, reduce_lr, model_checkpoint]\n",
        "\n",
        "# Fit the model.\n",
        "model_simple.fit(x=xtrain, batch_size=batch_size, epochs=epochs, \\\n",
        "          validation_data=(xtest, np.empty(0)), callbacks=callbacks, \\\n",
        "          verbose=0)\n",
        "\n",
        "print(\"Finished running deep hedging algorithm! (Simple Network)\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Node 'training/Adam/gradients/gradients/PartitionedCall_grad/PartitionedCall': Connecting to invalid output 1 of source node PartitionedCall which has 1 outputs.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-30054edd1d6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcertainty_equiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"certainty_equiv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEntropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_simple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcertainty_equiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel_simple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel_simple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py\u001b[0m in \u001b[0;36madd_loss\u001b[0;34m(self, losses, inputs)\u001b[0m\n\u001b[1;32m   1071\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0msymbolic_loss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msymbolic_losses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_is_graph_network'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_network_add_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m           \u001b[0;31m# Possible a loss was added in a Layer's `build`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_graph_network_add_loss\u001b[0;34m(self, symbolic_loss)\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_graph_network_add_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbolic_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1560\u001b[0;31m     \u001b[0mnew_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_subgraph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msymbolic_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1561\u001b[0m     \u001b[0;31m# Losses must be keyed on inputs no matter what in order to be supported in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m     \u001b[0;31m# DistributionStrategy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_subgraph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m   \"\"\"\n\u001b[0;32m-> 1813\u001b[0;31m   \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1814\u001b[0m   \u001b[0;31m# Keep only nodes and layers in the topology between inputs and outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1815\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mcreate_keras_history\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mkeras_tensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mTensors\u001b[0m \u001b[0mfound\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcame\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0ma\u001b[0m \u001b[0mKeras\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m   \"\"\"\n\u001b[0;32m--> 186\u001b[0;31m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreated_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_keras_history_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcreated_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    244\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m               \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m       \u001b[0mlayer_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munnest_if_single_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3595\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3597\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3598\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3599\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    525\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[0;31m# marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     is_initialized = session.run(\n\u001b[0;32m--> 939\u001b[0;31m         [variables_module.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    940\u001b[0m     \u001b[0;31m# TODO(kathywu): Some metric variables loaded from SavedModel are never\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[0;31m# actually used, and do not have an initializer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1181\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Node 'training/Adam/gradients/gradients/PartitionedCall_grad/PartitionedCall': Connecting to invalid output 1 of source node PartitionedCall which has 1 outputs."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6ykKzCDw8q7",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title <font color='Blue'>**Run the Deep Hedging Algorithm (Recurrent Network)!**</font>\n",
        "strategy_type = \"recurrent\"\n",
        "optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "# Setup and compile the model\n",
        "model_recurrent = Deep_Hedging(N=N, d=d+2, m=m, risk_free=risk_free, \\\n",
        "                      maturity=maturity).model( \\\n",
        "                      strategy_type=strategy_type, epsilon = epsilon, \\\n",
        "                      loss_type=loss_type, loss_param = loss_param)\n",
        "model_recurrent.compile(optimizer=optimizer)\n",
        "\n",
        "# Stopping criteria\n",
        "model_data_dir =\"./data/\"\n",
        "best_model_file = model_data_dir + \\\n",
        "          \"model_\" + strategy_type + \"_\"  + str(epsilon) + \".h5\"\n",
        "\n",
        "early_stopping = EarlyStopping(monitor=\"loss\", \\\n",
        "          patience=20, min_delta=1e-4, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"loss\", \\\n",
        "          factor=0.9, patience=2, min_delta=1e-3, verbose=0)\n",
        "model_checkpoint = ModelCheckpoint(best_model_file, \\\n",
        "          monitor=\"loss\", save_best_only=True, \\\n",
        "          save_weights_only=False, verbose=0)\n",
        "\n",
        "callbacks = [early_stopping, reduce_lr, model_checkpoint, TqdmCallback()]\n",
        "\n",
        "# Try to preload model weights if possible.\n",
        "try:\n",
        "  model_recurrent.load_weights(best_model_file)\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# Fit the model.\n",
        "model_fit = model_recurrent.fit(x=xtrain, batch_size=batch_size, epochs=epochs, \\\n",
        "            validation_data=(xtest, np.empty(0)), callbacks=callbacks, \\\n",
        "            verbose=0)\n",
        "model_recurrent.save(best_model_file)\n",
        "print(\"Finished running deep hedging algorithm! (Recurrent Network)\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1NKaQCzLoKL",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title <font color='Blue'>**Results: Option Prices**</font>\n",
        "report = Validation(model = model_simple, data = xtest, N = N, process = stochastic_process)\n",
        "\n",
        "# Specify the instrument as an European call option\n",
        "instrument = report.get_instrument(name = \"European_Call\", strike = strike, \\\n",
        "                                    maturity_date = maturity_date)\n",
        "\n",
        "BS_price = report.get_model_PV(instrument)\n",
        "risk_neutral_price = report.get_risk_neutral_PV()\n",
        "nn_simple_price = model_simple.evaluate(xtest, batch_size=batch_size, verbose=0)\n",
        "nn_recurrent_price = model_recurrent.evaluate(xtest, batch_size=batch_size, verbose=0)\n",
        "\n",
        "print(\"The Black-Scholes model price is %2.3f.\" % BS_price)\n",
        "print(\"The Risk Neutral price is %2.3f.\" % risk_neutral_price)\n",
        "print(\"The Deep Hedging (with simple network) price is %2.3f.\" % nn_simple_price)\n",
        "print(\"The Deep Hedging (with recurrent network) price is %2.3f.\" % nn_recurrent_price)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4z7UYxBZRE9",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title <font color='Blue'>**Results: Black-Scholes PnL vs Deep Hedging PnL**</font>\n",
        "\n",
        "# Compute Black-Scholes delta for each sample path at each time t.\n",
        "length_test_sample = len(S_test[0][:,0])\n",
        "model_delta = np.zeros((length_test_sample, N+1))\n",
        "func_delta = lambda i, j: report.get_model_delta(instrument, \\\n",
        "                s0=S_test[0][i,j], calculation_date=calculation_date + j)\n",
        "\n",
        "for j in trange(N+1):\n",
        "    model_delta[:,j]  = list(map(func_delta, range(length_test_sample), \\\n",
        "                            repeat(j,length_test_sample)))\n",
        "\n",
        "# Compute Black-Scholes PnL (for a short position, i.e. the Bank sells\n",
        "# a call option. The model delta from Quantlib is a long delta.\n",
        "PnL_BS = (np.multiply(S_test[0][:,0], -model_delta[:,0]) - \\\n",
        "          np.abs(model_delta[:,0])*S_test[0][:,0]*epsilon)* \\\n",
        "          np.exp(risk_free/num_days_in_a_year)\n",
        "for t in range(1, N):\n",
        "  PnL_BS += np.multiply(S_test[0][:,t], -model_delta[:,t] + model_delta[:,t-1]) - \\\n",
        "               np.abs(model_delta[:,t] -model_delta[:,t-1])*S_test[0][:,t]*epsilon\n",
        "  PnL_BS = PnL_BS*np.exp(risk_free/num_days_in_a_year)\n",
        "\n",
        "PnL_BS += (np.multiply(S_test[0][:,N],model_delta[:,N-1]) + option_payoff_test[0] - \\\n",
        "              np.abs(model_delta[:,N-1])*S_test[0][:,N]*epsilon)\n",
        "\n",
        "# Compute deep hedging PnL.\n",
        "[PnL_Deep_Hedge, certainty_equiv] = model_simple.predict(xtest,batch_size=1000,verbose=0)\n",
        "\n",
        "# Plot Black-Scholes PnL and Deep Hedging PnL (with BS_price charged on both).\n",
        "fig_PnL = plt.figure(dpi= 125, facecolor='w')\n",
        "fig_PnL.suptitle(\"Black-Scholes PnL vs Deep Hedging PnL \\n\", \\\n",
        "      fontweight=\"bold\")\n",
        "ax = fig_PnL.add_subplot()\n",
        "ax.set_title(\"Simple Network Structure with epsilon = \" + str(epsilon), \\\n",
        "      fontsize=8)\n",
        "ax.set_xlabel(\"PnL\")\n",
        "ax.set_ylabel(\"Frequency\")\n",
        "ax.hist((PnL_BS+BS_price, reshape_1D(PnL_Deep_Hedge+BS_price)), \\\n",
        "         bins=30, label=[\"Black-Scholes PnL\", \"Deep Hedging PnL\"])\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_MNSesPIMaz",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title <font color='Blue'>**Results: Black-Scholes Delta vs Deep Hedging Delta.**</font>\n",
        "for days_from_today in (1,15,29):\n",
        "  # x-axis: [Min_S, 10th percentile, ..., 90th percentile,  Max_S]\n",
        "  S_range = np.sort(S_test[0][:,days_from_today])\n",
        "  idx2select = np.append(np.arange(0, len(S_range), \\\n",
        "          int(len(S_range)/100)), len(S_range)-1)\n",
        "\n",
        "  # Compute NN delta.\n",
        "  submodel = Model(model_simple.input, model_simple.get_layer(\"dense_\" + str(d+1) \\\n",
        "                + \"_\" + str(days_from_today)).output)\n",
        "  nn_delta = submodel.predict(xtest, batch_size=1000,verbose=0)\n",
        "\n",
        "  tmp_stack = np.stack((S_test[0][:,days_from_today],reshape_1D(nn_delta)),axis=1)\n",
        "  tmp_stack = tmp_stack[tmp_stack[:,0].argsort()]\n",
        "  tmp_stack = tmp_stack[idx2select]\n",
        "\n",
        "  S_range = tmp_stack[:,0]\n",
        "  nn_delta = tmp_stack[:,1]\n",
        "\n",
        "  # Compute Black-Scholes delta for S_range.\n",
        "  model_delta = np.zeros(S_range.shape)\n",
        "  for i in range(len(S_range)):\n",
        "    model_delta[i] = report.get_model_delta(instrument, s0= S_range[i], \\\n",
        "            calculation_date=calculation_date + days_from_today)\n",
        "    \n",
        "  # Create a plot of Black-Scholes delta against deep hedging delta.\n",
        "  fig_delta = plt.figure(dpi= 125, facecolor='w')\n",
        "  fig_delta.suptitle(\"Black-Scholes Delta vs Deep Hedging Delta \\n\", \\\n",
        "        fontweight=\"bold\")\n",
        "  ax_delta = fig_delta.add_subplot()\n",
        "  ax_delta.set_title(\"Simple Network Structure with \" + \\\n",
        "              \"t=\" + str(days_from_today) + \", \" + \\\n",
        "                \"epsilon=\" + str(epsilon), \\\n",
        "                fontsize=8)\n",
        "  ax_delta.set_xlabel(\"Price of the Underlying Asset\")\n",
        "  ax_delta.set_ylabel(\"Delta\")\n",
        "  ax_delta.plot(S_range, model_delta, label=\"Black-Scholes Delta\")\n",
        "  ax_delta.scatter(S_range,nn_delta, c=\"red\", s=2, label=\"Deep Hedging Delta\")\n",
        "  ax_delta.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MD7DCgHmjiv",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title <font color='Blue'>**Results: Simple vs Recurrent Network**</font>\n",
        "\n",
        "# Compute deep hedging PnL for simple network.\n",
        "try:\n",
        "  tmp_model_str = model_data_dir + \\\n",
        "            \"model_\" + \"simple\" + \"_\"  + str(epsilon) + \".h5\"\n",
        "  model_simple = tf.keras.models.load_model(tmp_model_str )\t\n",
        "  [PnL_Deep_Hedge_simple, certainty_equiv] = \\\n",
        "            model_simple.predict(xtest,batch_size=1000,verbose=0)\n",
        "except:\n",
        "  print(\"File does not exist! You need to first run the simple network.\")\n",
        "\n",
        "# Compute deep hedging PnL for recurrent network.\n",
        "try:\n",
        "  tmp_model_str = model_data_dir + \\\n",
        "            \"model_\" + \"recurrent\" + \"_\"  + str(epsilon) + \".h5\"\n",
        "  model_recurrent = tf.keras.models.load_model(tmp_model_str )\t\n",
        "  [PnL_Deep_Hedge_recurrent, certainty_equiv] = \\\n",
        "            model_recurrent.predict(xtest,batch_size=1000,verbose=0)\n",
        "except:\n",
        "  print(\"File does not exist! You need to first run the recurrent network.\")\n",
        "\n",
        "# Plot Simple Network PnL vs Recurrent Network PnL (with BS_price charged on both).\n",
        "print(\"\\n\")\n",
        "fig_nn = plt.figure(dpi= 125, facecolor='w')\n",
        "fig_nn.suptitle(\"Simple Network PnL vs Recurrent Network PnL \\n \", \\\n",
        "      fontweight=\"bold\")\n",
        "ax = fig_nn.add_subplot()\n",
        "ax.set_title(\"epsilon = \" + str(epsilon), fontsize=8)\n",
        "ax.set_xlabel(\"PnL\")\n",
        "ax.set_ylabel(\"Frequency\")\n",
        "ax.hist((reshape_1D(PnL_Deep_Hedge_simple+BS_price), \\\n",
        "          reshape_1D(PnL_Deep_Hedge_recurrent+BS_price)), \\\n",
        "         bins=30, label=[\"Simple Network PnL\", \"Recurrent Network PnL\"])\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}